{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\hehe\\custom_lib\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from dotenv import load_dotenv\n",
    "from lightrag.utils import EmbeddingFunc\n",
    "from lightrag import LightRAG, QueryParam\n",
    "from lightrag.kg.shared_storage import initialize_pipeline_status\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# DIR to store the index files\n",
    "WORKING_DIR = \"./data_indexing\"\n",
    "\n",
    "load_dotenv()\n",
    "gemini_key = os.getenv(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Process 25376 Shared-Data created for Single Process\n",
      "INFO:nano-vectordb:Init {'embedding_dim': 768, 'metric': 'cosine', 'storage_file': './data_indexing\\\\vdb_entities.json'} 0 data\n",
      "INFO:nano-vectordb:Init {'embedding_dim': 768, 'metric': 'cosine', 'storage_file': './data_indexing\\\\vdb_relationships.json'} 0 data\n",
      "INFO:nano-vectordb:Init {'embedding_dim': 768, 'metric': 'cosine', 'storage_file': './data_indexing\\\\vdb_chunks.json'} 0 data\n",
      "INFO: Process 25376 initialized updated flags for namespace: [full_docs]\n",
      "INFO: Process 25376 ready to initialize storage namespace: [full_docs]\n",
      "INFO: Process 25376 initialized updated flags for namespace: [text_chunks]\n",
      "INFO: Process 25376 ready to initialize storage namespace: [text_chunks]\n",
      "INFO: Process 25376 initialized updated flags for namespace: [entities]\n",
      "INFO: Process 25376 initialized updated flags for namespace: [relationships]\n",
      "INFO: Process 25376 initialized updated flags for namespace: [chunks]\n",
      "INFO: Process 25376 initialized updated flags for namespace: [chunk_entity_relation]\n",
      "INFO: Process 25376 initialized updated flags for namespace: [llm_response_cache]\n",
      "INFO: Process 25376 ready to initialize storage namespace: [llm_response_cache]\n",
      "INFO: Process 25376 initialized updated flags for namespace: [doc_status]\n",
      "INFO: Process 25376 ready to initialize storage namespace: [doc_status]\n",
      "INFO: Process 25376 storage namespace already initialized: [full_docs]\n",
      "INFO: Process 25376 storage namespace already initialized: [text_chunks]\n",
      "INFO: Process 25376 storage namespace already initialized: [llm_response_cache]\n",
      "INFO: Process 25376 storage namespace already initialized: [doc_status]\n",
      "INFO: Process 25376 Pipeline namespace initialized\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(WORKING_DIR):\n",
    "    import shutil\n",
    "\n",
    "    shutil.rmtree(WORKING_DIR)\n",
    "\n",
    "os.mkdir(WORKING_DIR)\n",
    "\n",
    "\n",
    "async def llm_model_func(prompt, system_prompt=None, history_messages=[], keyword_extraction=False, **kwargs) -> str:\n",
    "    client = genai.Client(api_key=gemini_key)\n",
    "\n",
    "    if history_messages is None:\n",
    "        history_messages = []\n",
    "    combined_prompt = \"\"\n",
    "    if system_prompt:\n",
    "        combined_prompt += f\"{system_prompt}\\n\"\n",
    "    for msg in history_messages:\n",
    "        combined_prompt += f\"{msg['role']}: {msg['content']}\\n\"\n",
    "\n",
    "    combined_prompt += f\"user: {prompt}\"\n",
    "\n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemini-1.5-flash\",\n",
    "        contents=[combined_prompt],\n",
    "        config=types.GenerateContentConfig(max_output_tokens=500, temperature=0.1),\n",
    "    )\n",
    "\n",
    "    return response.text\n",
    "\n",
    "\n",
    "async def embedding_func(texts: list[str]) -> np.ndarray:\n",
    "    model = SentenceTransformer(\"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\")\n",
    "    embeddings = model.encode(texts, convert_to_numpy=True)\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "async def initialize_rag():\n",
    "    rag = LightRAG(\n",
    "        working_dir=WORKING_DIR,\n",
    "        llm_model_func=llm_model_func,\n",
    "        embedding_func=EmbeddingFunc(\n",
    "            embedding_dim=768,\n",
    "            max_token_size=8192,\n",
    "            func=embedding_func,\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    await rag.initialize_storages()\n",
    "    await initialize_pipeline_status()\n",
    "    return rag\n",
    "\n",
    "rag = asyncio.run(initialize_rag())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted document 0\n",
      "Inserted document 1\n",
      "Inserted document 2\n",
      "Inserted document 3\n",
      "Inserted document 4\n",
      "Inserted document 5\n",
      "Inserted document 6\n",
      "Inserted document 7\n",
      "Inserted document 8\n",
      "Inserted document 9\n",
      "Inserted document 10\n",
      "Inserted document 11\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import json\n",
    "import logging\n",
    "\n",
    "# Set the logging level to WARNING for specific libraries\n",
    "logging.getLogger(\"sentence_transformers\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"google_genai\").setLevel(logging.WARNING)\n",
    "\n",
    "with open('documents.json', 'r', encoding='utf-8') as f:\n",
    "    documents = json.load(f)  \n",
    "documents = list(documents.values())\n",
    "    \n",
    "idx = 0\n",
    "while idx < len(documents):\n",
    "    doc = documents[idx]\n",
    "    try:\n",
    "        rag.insert(doc)\n",
    "        print(f\"Inserted document {idx}\")\n",
    "        idx += 1 \n",
    "        if idx>11:\n",
    "            break\n",
    "    except Exception as e:\n",
    "        print(f\"Error inserting document {idx}: {e}\")\n",
    "        time.sleep(60)  # Wait for 60 seconds before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # thêm địa chỉ trường học vào graph\n",
    "# import json\n",
    "# with open('addresses.json', 'r', encoding='utf-8') as f:\n",
    "#     document = json.load(f)\n",
    "    \n",
    "# geos = list(set(document.values()))\n",
    "# mien_bac = ['Hà Nội', 'Hải Phòng', 'Bắc Ninh', 'Thái Nguyên', 'Thái Bình', 'Hải Dương', 'Vĩnh Phúc']\n",
    "# mien_trung = ['Huế', 'Thừa Thiên Huế', 'Đà Nẵng', 'Thanh Hóa', 'Nghệ An', 'Khánh Hòa', 'Đà Lạt']\n",
    "# mien_nam = ['Thành phố Hồ Chí Minh', 'Cần Thơ', 'Đồng Nai', 'Bình Dương', 'Long An', 'Hưng Yên']\n",
    "\n",
    "# def locate_geo(geo):\n",
    "#     if geo in mien_bac:\n",
    "#         return \"Miền Bắc\"\n",
    "#     elif geo in mien_trung:\n",
    "#         return \"Miền Trung\"\n",
    "#     elif geo in mien_nam:\n",
    "#         return \"Miền Nam\"\n",
    "#     else:\n",
    "#         return None\n",
    "# for locate in [\"Miền Bắc\", \"Miền Trung\", \"Miền Nam\"]:\n",
    "#     try:\n",
    "#         entity = rag.create_entity(locate, { \n",
    "#         \"description\": f\"{locate} là một miền của Việt Nam.\",\n",
    "#         \"entity_type\": \"geo\",\n",
    "#         })\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error creating entity for {locate}: {e}\")\n",
    "\n",
    "# for geo in geos:\n",
    "#     try:\n",
    "#         entity = rag.create_entity(geo,{ \n",
    "#         \"description\": f\"{geo} là một tỉnh thuộc {locate_geo(geo)} của Việt Nam.\",\n",
    "#         \"entity_type\": \"geo\",\n",
    "#         })\n",
    "        \n",
    "#         relation = rag.create_relation(geo, locate_geo(geo), {\n",
    "#         \"description\": f\"{geo} là một tỉnh thuộc {locate_geo(geo)} của Việt Nam.\",\n",
    "#         \"keywords\": f\"{locate_geo(geo)}, {geo}, tỉnh, thành phố\",\n",
    "#         \"weight\": 10.0\n",
    "#         })\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error creating entity for {geo}: {e}\")\n",
    "                \n",
    "# for school, geo in document.items():\n",
    "#     try:\n",
    "#         relation = rag.create_relation(school, geo, {\n",
    "#         \"description\": f\"{school} là một trường học tại {geo}.\",\n",
    "#         \"keywords\": f\"{geo}, {school}, tỉnh, thành phố\",\n",
    "#         \"weight\": 10.0\n",
    "#         })\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error creating relation for {school} {geo}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tôi không có thông tin về điểm chuẩn của tất cả các ngành tại Đại học Bách khoa Hà Nội.  Tuy nhiên, tôi có điểm chuẩn của một số ngành năm 2024: Khoa học máy tính (28,53), Kỹ thuật máy tính (28,48), Khoa học dữ liệu và Trí tuệ nhân tạo (28,22), Kỹ thuật điện tử viễn thông (27,12), Kỹ thuật điều khiển và tự động hóa (27,45), Kỹ thuật điện (25,85), và một số ngành khác.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = rag.query(\n",
    "    query= \"điểm các ngành của trường đại học bách khoa\",\n",
    "    param=QueryParam(mode=\"hybrid\", top_k=5, response_type=\"single line\", only_need_context=False),\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "custom_lib",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
