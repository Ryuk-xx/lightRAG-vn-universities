{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efbf9ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\hehe\\custom_lib\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "INFO: Process 3028 Shared-Data created for Single Process\n",
      "INFO: Process 3028 initialized updated flags for namespace: [full_docs]\n",
      "INFO: Process 3028 ready to initialize storage namespace: [full_docs]\n",
      "INFO: Process 3028 initialized updated flags for namespace: [text_chunks]\n",
      "INFO: Process 3028 ready to initialize storage namespace: [text_chunks]\n",
      "INFO: Process 3028 initialized updated flags for namespace: [entities]\n",
      "INFO: Process 3028 initialized updated flags for namespace: [relationships]\n",
      "INFO: Process 3028 initialized updated flags for namespace: [chunks]\n",
      "INFO: Process 3028 initialized updated flags for namespace: [chunk_entity_relation]\n",
      "INFO: Process 3028 initialized updated flags for namespace: [llm_response_cache]\n",
      "INFO: Process 3028 ready to initialize storage namespace: [llm_response_cache]\n",
      "INFO: Process 3028 initialized updated flags for namespace: [doc_status]\n",
      "INFO: Process 3028 ready to initialize storage namespace: [doc_status]\n"
     ]
    }
   ],
   "source": [
    "from lightrag import LightRAG, QueryParam\n",
    "from lightrag.utils import EmbeddingFunc\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import logging\n",
    "import json\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "\n",
    "load_dotenv()\n",
    "gemini_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "async def llm_model_func(prompt, system_prompt=None, history_messages=[], keyword_extraction=False, **kwargs) -> str:\n",
    "    client = genai.Client(api_key=gemini_key)\n",
    "\n",
    "    if history_messages is None:\n",
    "        history_messages = []\n",
    "    combined_prompt = \"\"\n",
    "    if system_prompt:\n",
    "        combined_prompt += f\"{system_prompt}\\n\"\n",
    "    for msg in history_messages:\n",
    "        combined_prompt += f\"{msg['role']}: {msg['content']}\\n\"\n",
    "        \n",
    "    combined_prompt += f\"user: {prompt}\"\n",
    "    \n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemini-1.5-pro\",\n",
    "        contents=[combined_prompt],\n",
    "        config=types.GenerateContentConfig(max_output_tokens=1000, temperature=0.1),\n",
    "    )\n",
    "    return response.text\n",
    "\n",
    "async def embedding_func(texts):\n",
    "    model = SentenceTransformer(\"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\")\n",
    "    embeddings = model.encode(texts, convert_to_numpy=True)\n",
    "    return embeddings\n",
    "\n",
    "rag: LightRAG = None\n",
    "\n",
    "async def init_rag():\n",
    "    global rag\n",
    "    rag = LightRAG(\n",
    "        working_dir=\"./data_indexing\",\n",
    "        llm_model_func=llm_model_func,\n",
    "        embedding_func=EmbeddingFunc(\n",
    "            embedding_dim=768,\n",
    "            max_token_size=8192,\n",
    "            func=embedding_func,\n",
    "        ),\n",
    "        auto_manage_storages_states=False,  \n",
    "    )\n",
    "    await rag.initialize_storages()\n",
    "\n",
    "async def process_query(user_query: str) -> str:\n",
    "    result = await rag.aquery(\n",
    "        query=user_query,\n",
    "        param=QueryParam(mode=\"mix\", top_k=10, response_type=\"Bullet Points\", stream=True),\n",
    "    )\n",
    "    return result\n",
    "file_path = r\".\\data_indexing\\kv_store_llm_response_cache.json\"\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    data = json.load(file)\n",
    "if \"mix\" in data:\n",
    "    data[\"mix\"] = {}\n",
    "with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "    json.dump(data, file, indent=4, ensure_ascii=False)\n",
    "    \n",
    "await init_rag()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc41fe47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* **Xếp hạng:**\n",
      "    * Đại học Quốc gia Hà Nội (VNU): Xếp hạng 851-900 thế giới (QS World University Rankings 2025), hạng 325 thế giới về phát triển bền vững, hạng 202 thế giới về kết quả tuyển dụng.  Lĩnh vực Khoa học Xã hội xếp hạng 501-600 thế giới, riêng ngành Xã hội học xếp hạng 301-375 thế giới.\n",
      "    * Học viện Báo chí và Tuyên truyền (AJC): Xếp hạng trong top 50 trường đại học hàng đầu tại Việt Nam (thường ở vị trí 40-45).\n",
      "\n",
      "* **Ngành học nổi bật:**\n",
      "    * VNU: Công nghệ thông tin, Toán học, Kinh tế.\n",
      "    * AJC: Báo chí (đặc biệt là Báo truyền hình), Quan hệ công chúng, Truyền thông đa phương tiện.\n",
      "\n",
      "* **Điểm chuẩn năm 2024 (một số ngành):**\n",
      "    * AJC:  Dao động từ 24,68 (Xây dựng Đảng và chính quyền nhà nước) đến 38,12 (Lịch sử). Các ngành báo chí nhóm ngành báo chí dao động từ 34,98 đến 37,25. Các ngành truyền thông dao động từ 28,05 đến 37,7.\n",
      "    * VNU: Không có thông tin điểm chuẩn cụ thể từ nguồn dữ liệu.\n",
      "\n",
      "* **Thông tin khác:**\n",
      "    * VNU: Có thế mạnh về khoa học tự nhiên, công nghệ và khoa học xã hội.\n",
      "    * AJC: Có thế mạnh về báo chí, truyền thông và quan hệ công chúng.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_query = \"So sánh đại học báo chí và tuyên truyền và đại học quốc gia Hà Nội?\"\n",
    "result = await process_query(user_query)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "custom_lib",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
